{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1240f2bc",
      "metadata": {
        "id": "1240f2bc"
      },
      "source": [
        "**1. What is a random variable in probability theory?**\n",
        "\n",
        " - A random variable is a variable that represents the outcomes of a random process or experiment. It can take different values based on chance, such as the result of rolling a die or flipping a coin. It helps us study probabilities in a structured mathematical way."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3c7e60",
      "metadata": {
        "id": "7e3c7e60"
      },
      "source": [
        "**2. What are the types of random variables?**\n",
        "\n",
        " - There are two main types of random variables: discrete and continuous. Discrete random variables have countable outcomes (like number of heads in 10 coin tosses), while continuous random variables have uncountable, measurable outcomes (like height or temperature). These types help in selecting the right probability model for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b4b66db",
      "metadata": {
        "id": "8b4b66db"
      },
      "source": [
        "**3. What is the difference between discrete and continuous distributions?**\n",
        "\n",
        " - A discrete distribution shows the probability of specific, countable outcomes (like rolling a 3 on a die). A continuous distribution shows probabilities over a range of values (like the chance someone's height is between 160–170 cm). Continuous uses curves; discrete uses probability at specific points."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da0b3180",
      "metadata": {
        "id": "da0b3180"
      },
      "source": [
        "**4. What are probability distribution functions (PDF)?**\n",
        "\n",
        " - A probability distribution function (PDF) describes how probabilities are spread across values of a random variable. For continuous variables, it gives the probability density, not exact probabilities. For discrete variables, it gives the actual probability of each possible outcome. The total probability in any PDF equals 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78c54cdd",
      "metadata": {
        "id": "78c54cdd"
      },
      "source": [
        "**5. How do cumulative distribution functions (CDF) differ from PDFs?**\n",
        "\n",
        " - A CDF shows the probability that a random variable is less than or equal to a certain value. Unlike a PDF, which gives the chance of an exact value (or density), a CDF gives a running total of probabilities up to that value. It always increases and ends at 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e5d7b63",
      "metadata": {
        "id": "6e5d7b63"
      },
      "source": [
        "**6. What is a discrete uniform distribution?**\n",
        "\n",
        " - A discrete uniform distribution is when all outcomes have the same probability. For example, rolling a fair six-sided die gives each number (1 to 6) a probability of 1/6. It’s called “uniform” because the probabilities are evenly distributed across all possible outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd355d05",
      "metadata": {
        "id": "dd355d05"
      },
      "source": [
        "**7. What are the key properties of a Bernoulli distribution?**\n",
        "\n",
        " - A Bernoulli distribution models a random experiment with only two outcomes: success (1) or failure (0). It has a single parameter p, which is the probability of success. It’s the simplest discrete distribution and forms the basis for more complex ones like the binomial distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b153747c",
      "metadata": {
        "id": "b153747c"
      },
      "source": [
        "**8. What is the binomial distribution, and how is it used in probability?**\n",
        "\n",
        " - The binomial distribution represents the number of successes in a fixed number of independent trials, each with the same probability of success. For example, it’s used to model the number of heads in 10 coin tosses. It’s useful in quality control, surveys, and many binary outcome scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc12745c",
      "metadata": {
        "id": "dc12745c"
      },
      "source": [
        "**9. What is the Poisson distribution and where is it applied?**\n",
        "\n",
        " - The Poisson distribution models the number of events that occur in a fixed interval of time or space, assuming events happen at a constant rate independently. It’s used in real-life applications like counting emails per hour, accidents at a crossing, or customer arrivals at a store."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d0b2d9b",
      "metadata": {
        "id": "8d0b2d9b"
      },
      "source": [
        "**10. What is a continuous uniform distribution?**\n",
        "\n",
        " - A continuous uniform distribution occurs when all outcomes in a continuous range are equally likely. For instance, if a train arrives at any time between 2 PM and 3 PM, the arrival time is uniformly distributed. The probability is constant over the interval and forms a flat curve."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed10e7ee",
      "metadata": {
        "id": "ed10e7ee"
      },
      "source": [
        "**11. What are the characteristics of a normal distribution?**\n",
        "\n",
        " - A normal distribution is a bell-shaped curve that is symmetric about its mean. Most data points lie close to the mean, and fewer occur as you move away. It’s defined by two parameters: the mean (center) and standard deviation (spread). Many natural and social phenomena follow this pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514d50a1",
      "metadata": {
        "id": "514d50a1"
      },
      "source": [
        "**12. What is the standard normal distribution, and why is it important?**\n",
        "\n",
        " - The standard normal distribution is a special case of the normal distribution with a mean of 0 and a standard deviation of 1. It’s important because it allows us to use standard tables and Z-scores to compare data across different normal distributions and perform hypothesis testing efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a7ee52c",
      "metadata": {
        "id": "4a7ee52c"
      },
      "source": [
        "**13. What is the Central Limit Theorem (CLT), and why is it critical in statistics?**\n",
        "\n",
        " - The Central Limit Theorem says that if you take enough random samples from any distribution, the distribution of their means will be approximately normal. It’s critical because it lets us use normal distribution tools (like confidence intervals and Z-tests) even if the original data isn’t normally distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb6d47e7",
      "metadata": {
        "id": "eb6d47e7"
      },
      "source": [
        "**14. How does the Central Limit Theorem relate to the normal distribution?**\n",
        "\n",
        " - The CLT explains why the normal distribution appears so frequently in statistics. It says that the average of many random samples tends to follow a normal distribution, no matter the shape of the original data. This justifies using normal-based methods in many practical situations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30676b73",
      "metadata": {
        "id": "30676b73"
      },
      "source": [
        "**15. What is the application of Z statistics in hypothesis testing?**\n",
        "\n",
        " - Z statistics are used in hypothesis testing to compare sample results with a known population. They help determine if the difference is significant or just random. If the Z-value is very high or low, it means the result is unusual under the null hypothesis and may lead to rejection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52398ba",
      "metadata": {
        "id": "c52398ba"
      },
      "source": [
        "**16. How do you calculate a Z-score, and what does it represent?**\n",
        "\n",
        " - A Z-score is calculated by subtracting the mean from a value and dividing the result by the standard deviation. It tells you how many standard deviations the value is from the mean. A positive Z-score means above average; a negative means below average."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f8ff56a",
      "metadata": {
        "id": "0f8ff56a"
      },
      "source": [
        "**17. What are point estimates and interval estimates in statistics?**\n",
        "\n",
        " - A point estimate gives a single value as an estimate of a population parameter, like the average height of students. An interval estimate, like a confidence interval, gives a range of values that likely contains the parameter. Interval estimates provide more information and reflect uncertainty better."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c984cdbb",
      "metadata": {
        "id": "c984cdbb"
      },
      "source": [
        "**18. What is the significance of confidence intervals in statistical analysis?**\n",
        "\n",
        "- Confidence intervals give a range in which we expect the true population parameter to fall. For example, a 95% confidence interval means that if we repeated the experiment many times, 95% of the intervals would contain the true value. It’s useful for making decisions with limited data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aee1c1c",
      "metadata": {
        "id": "4aee1c1c"
      },
      "source": [
        "**19. What is the relationship between a Z-score and a confidence interval?**\n",
        "\n",
        " - Z-scores are used to build confidence intervals in normal distributions. For example, a Z-score of 1.96 corresponds to a 95% confidence interval. The Z-value helps determine the margin of error added or subtracted from the sample mean to create the interval."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e8e07d",
      "metadata": {
        "id": "85e8e07d"
      },
      "source": [
        "**20. How are Z-scores used to compare different distributions?**\n",
        "\n",
        "- Z-scores convert different data values into a common scale (in standard deviations), so you can compare them even if they come from different distributions. For example, you can compare a test score in math with one in English, even if the averages and spreads are different."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3164d159",
      "metadata": {
        "id": "3164d159"
      },
      "source": [
        "**21. What are the assumptions for applying the Central Limit Theorem?**\n",
        "\n",
        " - The Central Limit Theorem assumes that samples are independent, drawn randomly, and that the sample size is large enough (usually n ≥ 30). If the population distribution is already normal, a smaller sample is fine. These conditions ensure the sampling distribution of the mean is approximately normal."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "284f910d",
      "metadata": {
        "id": "284f910d"
      },
      "source": [
        "**22. What is the concept of expected value in a probability distribution?**\n",
        "\n",
        " - The expected value is the long-run average outcome of a random variable if an experiment is repeated many times. It’s calculated by multiplying each possible value by its probability and summing the results. For example, in a fair die roll, the expected value is 3.5."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5456a034",
      "metadata": {
        "id": "5456a034"
      },
      "source": [
        "**23. How does a probability distribution relate to the expected outcome of a random variable?**\n",
        "\n",
        " - A probability distribution shows all possible outcomes and their likelihoods for a random variable. The expected outcome (expected value) is a weighted average of those outcomes, where each is weighted by its probability. It summarizes the average result you'd expect from many repetitions of the random process."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}